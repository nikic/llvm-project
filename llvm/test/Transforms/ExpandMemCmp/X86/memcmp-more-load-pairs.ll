; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; NOTE: This is a copy of llvm/test/CodeGen/X86/memcmp.ll with more load pairs. Please keep it that way.
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4  -mtriple=x86_64-unknown-unknown               < %s | FileCheck %s --check-prefixes=X64
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=sse4.1 < %s | FileCheck %s --check-prefixes=X64-SSE41
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx    < %s | FileCheck %s --check-prefixes=X64-AVX1
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx2   < %s | FileCheck %s --check-prefixes=X64-AVX2
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx512bw,+prefer-256-bit < %s | FileCheck %s --check-prefixes=X64-AVX512BW-256
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx512bw,-prefer-256-bit < %s | FileCheck %s --check-prefixes=X64-AVX512BW
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx512f,+prefer-256-bit,-prefer-mask-registers < %s | FileCheck %s --check-prefixes=X64-AVX512F-256
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx512f,-prefer-256-bit,-prefer-mask-registers < %s | FileCheck %s --check-prefixes=X64-AVX512F
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx512f,+prefer-256-bit,+prefer-mask-registers < %s | FileCheck %s --check-prefixes=X64-MIC-AVX2
; RUN: opt -S -passes=expand-memcmp -max-loads-per-memcmp=4 -memcmp-num-loads-per-block=4 -mtriple=x86_64-unknown-unknown -mattr=avx512f,-prefer-256-bit,+prefer-mask-registers < %s | FileCheck %s --check-prefixes=X64-MIC-AVX512F

; This tests codegen time inlining/optimization of memcmp
; rdar://6480398

@.str = private constant [513 x i8] c"01234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901\00", align 1

declare dso_local i32 @memcmp(ptr, ptr, i64)

define i32 @length0(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length0(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0:[0-9]+]] {
; X64-NEXT:    ret i32 0
;
; X64-SSE41-LABEL: define i32 @length0(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-SSE41-NEXT:    ret i32 0
;
; X64-AVX1-LABEL: define i32 @length0(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-AVX1-NEXT:    ret i32 0
;
; X64-AVX2-LABEL: define i32 @length0(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-AVX2-NEXT:    ret i32 0
;
; X64-AVX512BW-256-LABEL: define i32 @length0(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-AVX512BW-256-NEXT:    ret i32 0
;
; X64-AVX512BW-LABEL: define i32 @length0(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-AVX512BW-NEXT:    ret i32 0
;
; X64-AVX512F-256-LABEL: define i32 @length0(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-AVX512F-256-NEXT:    ret i32 0
;
; X64-AVX512F-LABEL: define i32 @length0(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-AVX512F-NEXT:    ret i32 0
;
; X64-MIC-AVX2-LABEL: define i32 @length0(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-MIC-AVX2-NEXT:    ret i32 0
;
; X64-MIC-AVX512F-LABEL: define i32 @length0(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-MIC-AVX512F-NEXT:    ret i32 0
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 0) nounwind
  ret i32 %m
  }

define i1 @length0_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length0_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    ret i1 true
;
; X64-SSE41-LABEL: define i1 @length0_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    ret i1 true
;
; X64-AVX1-LABEL: define i1 @length0_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    ret i1 true
;
; X64-AVX2-LABEL: define i1 @length0_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    ret i1 true
;
; X64-AVX512BW-256-LABEL: define i1 @length0_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    ret i1 true
;
; X64-AVX512BW-LABEL: define i1 @length0_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    ret i1 true
;
; X64-AVX512F-256-LABEL: define i1 @length0_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    ret i1 true
;
; X64-AVX512F-LABEL: define i1 @length0_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    ret i1 true
;
; X64-MIC-AVX2-LABEL: define i1 @length0_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    ret i1 true
;
; X64-MIC-AVX512F-LABEL: define i1 @length0_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    ret i1 true
;





  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 0) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length0_lt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length0_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    ret i1 false
;
; X64-SSE41-LABEL: define i1 @length0_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    ret i1 false
;
; X64-AVX1-LABEL: define i1 @length0_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    ret i1 false
;
; X64-AVX2-LABEL: define i1 @length0_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    ret i1 false
;
; X64-AVX512BW-256-LABEL: define i1 @length0_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    ret i1 false
;
; X64-AVX512BW-LABEL: define i1 @length0_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    ret i1 false
;
; X64-AVX512F-256-LABEL: define i1 @length0_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    ret i1 false
;
; X64-AVX512F-LABEL: define i1 @length0_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    ret i1 false
;
; X64-MIC-AVX2-LABEL: define i1 @length0_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    ret i1 false
;
; X64-MIC-AVX512F-LABEL: define i1 @length0_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    ret i1 false
;





  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 0) nounwind
  %c = icmp slt i32 %m, 0
  ret i1 %c
}

define i32 @length2(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length2(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    ret i32 [[TMP7]]
;
; X64-SSE41-LABEL: define i32 @length2(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-SSE41-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-SSE41-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    ret i32 [[TMP7]]
;
; X64-AVX1-LABEL: define i32 @length2(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX1-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    ret i32 [[TMP7]]
;
; X64-AVX2-LABEL: define i32 @length2(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX2-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    ret i32 [[TMP7]]
;
; X64-AVX512BW-256-LABEL: define i32 @length2(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    ret i32 [[TMP7]]
;
; X64-AVX512BW-LABEL: define i32 @length2(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    ret i32 [[TMP7]]
;
; X64-AVX512F-256-LABEL: define i32 @length2(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    ret i32 [[TMP7]]
;
; X64-AVX512F-LABEL: define i32 @length2(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    ret i32 [[TMP7]]
;
; X64-MIC-AVX2-LABEL: define i32 @length2(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    ret i32 [[TMP7]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length2(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[TMP7]]
;










  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 2) nounwind
  ret i32 %m
}

define i1 @length2_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length2_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length2_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length2_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length2_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length2_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length2_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length2_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length2_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length2_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length2_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i16 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;








  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 2) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length2_lt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length2_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length2_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-SSE41-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-SSE41-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length2_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX1-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length2_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX2-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length2_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length2_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length2_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length2_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length2_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length2_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp slt i32 [[TMP7]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;











  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 2) nounwind
  %c = icmp slt i32 %m, 0
  ret i1 %c
}

define i1 @length2_gt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length2_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length2_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-SSE41-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-SSE41-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length2_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX1-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length2_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX2-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length2_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length2_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length2_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length2_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length2_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length2_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i16 @llvm.bswap.i16(i16 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = zext i16 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = zext i16 [[TMP4]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = sub i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp sgt i32 [[TMP7]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;











  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 2) nounwind
  %c = icmp sgt i32 %m, 0
  ret i1 %c
}

define i1 @length2_eq_const(ptr %X) nounwind {
; X64-LABEL: define i1 @length2_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-NEXT:    ret i1 [[TMP2]]
;
; X64-SSE41-LABEL: define i1 @length2_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-SSE41-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX1-LABEL: define i1 @length2_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-AVX1-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX2-LABEL: define i1 @length2_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512BW-256-LABEL: define i1 @length2_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512BW-LABEL: define i1 @length2_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512F-256-LABEL: define i1 @length2_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512F-LABEL: define i1 @length2_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP2]]
;
; X64-MIC-AVX2-LABEL: define i1 @length2_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP2]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length2_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i16 [[TMP1]], 12849
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP2]]
;






  %m = tail call i32 @memcmp(ptr %X, ptr getelementptr inbounds ([513 x i8], ptr @.str, i32 0, i32 1), i64 2) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i1 @length2_eq_nobuiltin_attr(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR3:[0-9]+]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length2_eq_nobuiltin_attr(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 2) #[[ATTR4:[0-9]+]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;





  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 2) nounwind nobuiltin
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length3(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length3(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-NEXT:    br label [[ENDBLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length3(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-SSE41-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br label [[ENDBLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length3(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX1-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br label [[ENDBLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length3(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX2-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br label [[ENDBLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length3(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length3(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length3(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length3(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length3(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length3(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i16 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i16 @llvm.bswap.i16(i16 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i16 @llvm.bswap.i16(i16 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i16 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:



; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 3) nounwind
  ret i32 %m
}

define i1 @length3_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length3_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-NEXT:    ret i1 [[TMP12]]
;
; X64-SSE41-LABEL: define i1 @length3_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-SSE41-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-SSE41-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX1-LABEL: define i1 @length3_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX2-LABEL: define i1 @length3_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512BW-256-LABEL: define i1 @length3_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512BW-LABEL: define i1 @length3_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-256-LABEL: define i1 @length3_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-LABEL: define i1 @length3_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX2-LABEL: define i1 @length3_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length3_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i16, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i16, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i16 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 2
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 2
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i16
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i16
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i16 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i16 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i16 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP12]]
;
















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 3) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i32 @length4(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length4(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-NEXT:    ret i32 [[TMP9]]
;
; X64-SSE41-LABEL: define i32 @length4(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-SSE41-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-SSE41-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-SSE41-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-SSE41-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX1-LABEL: define i32 @length4(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX1-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX1-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX1-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX1-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX2-LABEL: define i32 @length4(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX2-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX2-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX2-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX2-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512BW-256-LABEL: define i32 @length4(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512BW-LABEL: define i32 @length4(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512BW-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512F-256-LABEL: define i32 @length4(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512F-256-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512F-LABEL: define i32 @length4(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512F-NEXT:    ret i32 [[TMP9]]
;
; X64-MIC-AVX2-LABEL: define i32 @length4(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    ret i32 [[TMP9]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length4(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[TMP9]]
;












  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 4) nounwind
  ret i32 %m
}

define i1 @length4_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length4_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-NEXT:    ret i1 [[TMP3]]
;
; X64-SSE41-LABEL: define i1 @length4_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX1-LABEL: define i1 @length4_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX2-LABEL: define i1 @length4_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512BW-256-LABEL: define i1 @length4_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512BW-LABEL: define i1 @length4_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512F-256-LABEL: define i1 @length4_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512F-LABEL: define i1 @length4_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP3]]
;
; X64-MIC-AVX2-LABEL: define i1 @length4_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP3]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length4_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i32 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP3]]
;







  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 4) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i1 @length4_lt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length4_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-NEXT:    ret i1 [[TMP5]]
;
; X64-SSE41-LABEL: define i1 @length4_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-SSE41-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX1-LABEL: define i1 @length4_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX1-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX2-LABEL: define i1 @length4_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX2-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512BW-256-LABEL: define i1 @length4_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512BW-LABEL: define i1 @length4_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512F-256-LABEL: define i1 @length4_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-256-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512F-LABEL: define i1 @length4_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-NEXT:    ret i1 [[TMP5]]
;
; X64-MIC-AVX2-LABEL: define i1 @length4_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP5]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length4_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ult i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP5]]
;








  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 4) nounwind
  %c = icmp slt i32 %m, 0
  ret i1 %c
}

define i1 @length4_gt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length4_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-NEXT:    ret i1 [[TMP5]]
;
; X64-SSE41-LABEL: define i1 @length4_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-SSE41-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX1-LABEL: define i1 @length4_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX1-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX2-LABEL: define i1 @length4_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX2-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512BW-256-LABEL: define i1 @length4_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512BW-LABEL: define i1 @length4_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512BW-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512F-256-LABEL: define i1 @length4_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-256-NEXT:    ret i1 [[TMP5]]
;
; X64-AVX512F-LABEL: define i1 @length4_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-AVX512F-NEXT:    ret i1 [[TMP5]]
;
; X64-MIC-AVX2-LABEL: define i1 @length4_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP5]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length4_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ugt i32 [[TMP3]], [[TMP4]]
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP5]]
;








  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 4) nounwind
  %c = icmp sgt i32 %m, 0
  ret i1 %c
}

define i1 @length4_eq_const(ptr %X) nounwind {
; X64-LABEL: define i1 @length4_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length4_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-SSE41-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length4_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-AVX1-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length4_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length4_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length4_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length4_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length4_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length4_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length4_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i32 [[TMP1]], 875770417
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;







  %m = tail call i32 @memcmp(ptr %X, ptr getelementptr inbounds ([513 x i8], ptr @.str, i32 0, i32 1), i64 4) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length5(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length5(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-NEXT:    br label [[ENDBLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length5(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-SSE41-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br label [[ENDBLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length5(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX1-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br label [[ENDBLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length5(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX2-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br label [[ENDBLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length5(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length5(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length5(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length5(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length5(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length5(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:



; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 5) nounwind
  ret i32 %m
}

define i1 @length5_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length5_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-NEXT:    ret i1 [[TMP12]]
;
; X64-SSE41-LABEL: define i1 @length5_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-SSE41-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-SSE41-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX1-LABEL: define i1 @length5_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX2-LABEL: define i1 @length5_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512BW-256-LABEL: define i1 @length5_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512BW-LABEL: define i1 @length5_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-256-LABEL: define i1 @length5_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-LABEL: define i1 @length5_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX2-LABEL: define i1 @length5_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length5_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i32 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i32 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP12]]
;
















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 5) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i1 @length5_lt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length5_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-NEXT:    br label [[ENDBLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length5_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-SSE41-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br label [[ENDBLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length5_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX1-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br label [[ENDBLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length5_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX2-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br label [[ENDBLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length5_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length5_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length5_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length5_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br label [[ENDBLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length5_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length5_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[TMP5:%.*]], [[TMP6:%.*]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1:%.*]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 4
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 4
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i8, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i8, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = zext i8 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i8 [[TMP11]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = sub i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ [[TMP14]], [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;



; X64-SSE2:       res_block:



; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:



  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 5) nounwind
  %c = icmp slt i32 %m, 0
  ret i1 %c
}

define i32 @length7(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length7(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length7(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length7(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length7(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length7(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length7(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length7(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length7(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length7(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length7(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 7) nounwind
  ret i32 %m
}

define i1 @length7_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length7_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    ret i1 [[TMP10]]
;
; X64-SSE41-LABEL: define i1 @length7_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX1-LABEL: define i1 @length7_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX2-LABEL: define i1 @length7_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512BW-256-LABEL: define i1 @length7_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512BW-LABEL: define i1 @length7_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-256-LABEL: define i1 @length7_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-LABEL: define i1 @length7_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX2-LABEL: define i1 @length7_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length7_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i32 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i32 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP10]]
;














  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 7) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i1 @length7_lt(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length7_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length7_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length7_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length7_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length7_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length7_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length7_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length7_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length7_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length7_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i32 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i32 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i32, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i32, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i32 @llvm.bswap.i32(i32 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i32 @llvm.bswap.i32(i32 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:



  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 7) nounwind
  %c = icmp slt i32 %m, 0
  ret i1 %c
}

define i32 @length8(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length8(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-NEXT:    ret i32 [[TMP9]]
;
; X64-SSE41-LABEL: define i32 @length8(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-SSE41-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-SSE41-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-SSE41-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-SSE41-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-SSE41-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-SSE41-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX1-LABEL: define i32 @length8(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-AVX1-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-AVX1-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-AVX1-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-AVX1-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX1-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX1-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX2-LABEL: define i32 @length8(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-AVX2-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-AVX2-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-AVX2-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-AVX2-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX2-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX2-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512BW-256-LABEL: define i32 @length8(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512BW-LABEL: define i32 @length8(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512BW-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512F-256-LABEL: define i32 @length8(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512F-256-NEXT:    ret i32 [[TMP9]]
;
; X64-AVX512F-LABEL: define i32 @length8(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-AVX512F-NEXT:    ret i32 [[TMP9]]
;
; X64-MIC-AVX2-LABEL: define i32 @length8(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    ret i32 [[TMP9]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length8(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP1]])
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = call i64 @llvm.bswap.i64(i64 [[TMP2]])
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = icmp ugt i64 [[TMP3]], [[TMP4]]
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[TMP3]], [[TMP4]]
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = zext i1 [[TMP5]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP6]] to i32
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = sub i32 [[TMP7]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[TMP9]]
;












  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 8) nounwind
  ret i32 %m
}

define i1 @length8_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length8_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length8_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length8_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length8_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length8_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length8_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length8_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length8_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length8_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length8_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;








  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 8) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length8_eq_const(ptr %X) nounwind {
; X64-LABEL: define i1 @length8_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-NEXT:    ret i1 [[TMP2]]
;
; X64-SSE41-LABEL: define i1 @length8_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-SSE41-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX1-LABEL: define i1 @length8_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-AVX1-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX2-LABEL: define i1 @length8_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512BW-256-LABEL: define i1 @length8_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512BW-LABEL: define i1 @length8_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512F-256-LABEL: define i1 @length8_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512F-LABEL: define i1 @length8_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP2]]
;
; X64-MIC-AVX2-LABEL: define i1 @length8_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP2]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length8_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i64 [[TMP1]], 3978425819141910832
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP2]]
;






  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 8) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i1 @length9_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length9_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length9_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-SSE41-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-SSE41-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length9_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length9_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length9_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length9_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length9_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length9_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length9_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length9_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i8, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i8, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i8 [[TMP6]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i8 [[TMP7]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;

















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 9) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length10_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length10_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length10_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-SSE41-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-SSE41-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length10_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length10_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length10_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length10_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length10_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length10_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length10_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length10_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i16, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i16, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i16 [[TMP6]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i16 [[TMP7]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;

















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 10) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length11_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length11_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length11_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length11_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length11_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length11_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length11_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length11_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length11_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length11_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length11_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 3
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 11) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length12_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length12_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-NEXT:    ret i1 [[TMP12]]
;
; X64-SSE41-LABEL: define i1 @length12_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-SSE41-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-SSE41-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX1-LABEL: define i1 @length12_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX2-LABEL: define i1 @length12_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512BW-256-LABEL: define i1 @length12_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512BW-LABEL: define i1 @length12_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-256-LABEL: define i1 @length12_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-LABEL: define i1 @length12_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX2-LABEL: define i1 @length12_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length12_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i32, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i32, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP6]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i32 [[TMP7]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i64 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i64 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i64 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP12]]
;
















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 12) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i32 @length12(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length12(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length12(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-SSE41-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-SSE41-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-SSE41-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length12(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-AVX1-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-AVX1-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-AVX1-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length12(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-AVX2-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-AVX2-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-AVX2-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length12(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length12(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-AVX512BW-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-AVX512BW-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length12(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-AVX512F-256-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length12(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-AVX512F-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-AVX512F-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length12(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length12(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP14:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP15:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i32, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i32, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = call i32 @llvm.bswap.i32(i32 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14]] = zext i32 [[TMP12]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP15]] = zext i32 [[TMP13]] to i64
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = icmp eq i64 [[TMP14]], [[TMP15]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP16]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:










; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 12) nounwind
  ret i32 %m
}

define i1 @length13_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length13_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length13_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length13_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length13_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length13_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length13_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length13_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length13_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length13_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length13_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 5
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 5
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 13) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length14_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length14_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length14_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length14_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length14_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length14_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length14_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length14_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length14_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length14_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length14_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 6
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 6
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 14) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i1 @length15_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @length15_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length15_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length15_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length15_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length15_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length15_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length15_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length15_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length15_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length15_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i64 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 7
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 7
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i64 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i64 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i64 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;















  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 15) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

; PR33329 - https://bugs.llvm.org/show_bug.cgi?id=33329

define i32 @length16(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length16(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length16(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length16(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length16(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length16(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length16(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length16(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length16(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length16(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length16(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 16) nounwind
  ret i32 %m
}

define i1 @length16_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length16_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-NEXT:    ret i1 [[TMP3]]
;
; X64-SSE41-LABEL: define i1 @length16_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX1-LABEL: define i1 @length16_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX2-LABEL: define i1 @length16_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512BW-256-LABEL: define i1 @length16_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512BW-LABEL: define i1 @length16_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512F-256-LABEL: define i1 @length16_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512F-LABEL: define i1 @length16_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP3]]
;
; X64-MIC-AVX2-LABEL: define i1 @length16_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP3]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length16_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX-LABEL: length16_eq:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vpxor (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    setne %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length16_eq:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %xmm1
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; X64-MIC-AVX-NEXT:    kortestw %k0, %k0
; X64-MIC-AVX-NEXT:    setne %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 16) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length16_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length16_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length16_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length16_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length16_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length16_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length16_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length16_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length16_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length16_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length16_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 16) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length16_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length16_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length16_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length16_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length16_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length16_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length16_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length16_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length16_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length16_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length16_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB1]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 16) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length16_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length16_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length16_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length16_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX1-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length16_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length16_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length16_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length16_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length16_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length16_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length16_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP3]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-AVX-LABEL: length16_eq_const:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    sete %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length16_eq_const:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} xmm1 = [858927408,926299444,825243960,892613426]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; X64-MIC-AVX-NEXT:    kortestw %k0, %k0
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 16) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

; PR33914 - https://bugs.llvm.org/show_bug.cgi?id=33914

define i32 @length24(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length24(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length24(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length24(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length24(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length24(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length24(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length24(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length24(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length24(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length24(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 24) nounwind
  ret i32 %m
}

define i1 @length24_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length24_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length24_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-SSE41-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-SSE41-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-SSE41-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length24_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length24_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length24_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length24_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length24_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length24_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length24_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length24_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i64, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i64, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i64 [[TMP6]] to i128
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i64 [[TMP7]] to i128
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i128 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i128 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i128 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX-LABEL: length24_eq:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovq {{.*#+}} xmm1 = mem[0],zero
; X64-AVX-NEXT:    vmovq {{.*#+}} xmm2 = mem[0],zero
; X64-AVX-NEXT:    vpxor %xmm2, %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm0, %xmm1, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    sete %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length24_eq:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %xmm1
; X64-MIC-AVX-NEXT:    vmovq {{.*#+}} xmm2 = mem[0],zero
; X64-MIC-AVX-NEXT:    vmovq {{.*#+}} xmm3 = mem[0],zero
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm2, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 24) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length24_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length24_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length24_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length24_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length24_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length24_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length24_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length24_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length24_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length24_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length24_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 24) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length24_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length24_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length24_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length24_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length24_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length24_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length24_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length24_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length24_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length24_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length24_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB2]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 24) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length24_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length24_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-NEXT:    ret i1 [[TMP8]]
;
; X64-SSE41-LABEL: define i1 @length24_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-SSE41-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-SSE41-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-SSE41-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-SSE41-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-SSE41-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX1-LABEL: define i1 @length24_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-AVX1-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-AVX1-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-AVX1-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX2-LABEL: define i1 @length24_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-AVX2-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-AVX2-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-AVX2-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512BW-256-LABEL: define i1 @length24_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512BW-LABEL: define i1 @length24_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512F-256-LABEL: define i1 @length24_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512F-LABEL: define i1 @length24_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP8]]
;
; X64-MIC-AVX2-LABEL: define i1 @length24_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP8]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length24_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = zext i64 [[TMP4]] to i128
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = xor i128 [[TMP5]], 3689065127958034230
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = or i128 [[TMP2]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = icmp ne i128 [[TMP7]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX-LABEL: length24_eq_const:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovq {{.*#+}} xmm1 = mem[0],zero
; X64-AVX-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    setne %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length24_eq_const:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovq {{.*#+}} xmm1 = mem[0],zero
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} xmm2 = [959985462,858927408,0,0]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} xmm1 = [858927408,926299444,825243960,892613426]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    setne %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 24) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i32 @length31(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length31(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64:       loadbb3:
; X64-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length31(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb3:
; X64-SSE41-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-SSE41-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-SSE41-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-SSE41-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-SSE41-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-SSE41-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-SSE41-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-SSE41-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length31(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb3:
; X64-AVX1-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX1-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX1-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX1-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX1-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX1-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX1-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX1-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length31(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb3:
; X64-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length31(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb3:
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512BW-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length31(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb3:
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512BW-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length31(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb3:
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512F-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length31(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb3:
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length31(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb3:
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-MIC-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length31(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb3:
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-MIC-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       loadbb3:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 31) nounwind
  ret i32 %m
}

define i1 @length31_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length31_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length31_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length31_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length31_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length31_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length31_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length31_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length31_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length31_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length31_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX-LABEL: length31_eq:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovdqu 15(%rdi), %xmm1
; X64-AVX-NEXT:    vpxor 15(%rsi), %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    sete %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length31_eq:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu 15(%rdi), %xmm1
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %xmm2
; X64-MIC-AVX-NEXT:    vmovdqu 15(%rsi), %xmm3
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 31) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length31_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length31_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64:       loadbb3:
; X64-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length31_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb3:
; X64-SSE41-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-SSE41-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-SSE41-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-SSE41-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-SSE41-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-SSE41-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-SSE41-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-SSE41-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length31_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb3:
; X64-AVX1-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX1-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX1-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX1-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX1-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX1-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX1-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX1-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length31_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb3:
; X64-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length31_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb3:
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512BW-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length31_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb3:
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512BW-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length31_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb3:
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512F-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length31_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb3:
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length31_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb3:
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-MIC-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length31_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb3:
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-MIC-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       loadbb3:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 31) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length31_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length31_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64:       loadbb3:
; X64-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length31_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb3:
; X64-SSE41-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-SSE41-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-SSE41-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-SSE41-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-SSE41-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-SSE41-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-SSE41-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-SSE41-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length31_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb3:
; X64-AVX1-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX1-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX1-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX1-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX1-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX1-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX1-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX1-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length31_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb3:
; X64-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length31_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb3:
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512BW-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length31_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb3:
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512BW-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length31_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb3:
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512F-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length31_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb3:
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length31_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb3:
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-MIC-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length31_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb3:
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 23
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 23
; X64-MIC-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       loadbb3:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 31) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length31_eq_prefer128(ptr %x, ptr %y) nounwind "prefer-vector-width"="128" {
;
; X64-LABEL: define i1 @length31_eq_prefer128(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1:[0-9]+]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length31_eq_prefer128(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length31_eq_prefer128(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length31_eq_prefer128(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length31_eq_prefer128(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length31_eq_prefer128(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length31_eq_prefer128(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length31_eq_prefer128(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length31_eq_prefer128(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length31_eq_prefer128(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2:[0-9]+]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 15
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX-LABEL: length31_eq_prefer128:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovdqu 15(%rdi), %xmm1
; X64-AVX-NEXT:    vpxor 15(%rsi), %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    sete %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length31_eq_prefer128:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu 15(%rdi), %xmm1
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %xmm2
; X64-MIC-AVX-NEXT:    vmovdqu 15(%rsi), %xmm3
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 31) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length31_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length31_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-NEXT:    ret i1 [[TMP7]]
;
; X64-SSE41-LABEL: define i1 @length31_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-SSE41-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-SSE41-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX1-LABEL: define i1 @length31_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-AVX1-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX2-LABEL: define i1 @length31_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-AVX2-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX512BW-256-LABEL: define i1 @length31_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX512BW-LABEL: define i1 @length31_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX512F-256-LABEL: define i1 @length31_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX512F-LABEL: define i1 @length31_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP7]]
;
; X64-MIC-AVX2-LABEL: define i1 @length31_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP7]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length31_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 15
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 64100044907875699958541276911416849973
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX-LABEL: length31_eq_const:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovdqu 15(%rdi), %xmm1
; X64-AVX-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    setne %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length31_eq_const:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu 15(%rdi), %xmm1
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} xmm2 = [943142453,842084409,909456435,809056311]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} xmm1 = [858927408,926299444,825243960,892613426]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    setne %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 31) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i32 @length32(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length32(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64:       loadbb3:
; X64-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    ret i32 [[PHI_RES]]
;
; X64-SSE41-LABEL: define i32 @length32(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb3:
; X64-SSE41-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-SSE41-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-SSE41-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-SSE41-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-SSE41-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-SSE41-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-SSE41-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-SSE41-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX1-LABEL: define i32 @length32(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb3:
; X64-AVX1-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX1-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX1-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX1-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX1-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX1-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX1-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX1-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX2-LABEL: define i32 @length32(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb3:
; X64-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-256-LABEL: define i32 @length32(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb3:
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512BW-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512BW-LABEL: define i32 @length32(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb3:
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512BW-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-256-LABEL: define i32 @length32(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb3:
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512F-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    ret i32 [[PHI_RES]]
;
; X64-AVX512F-LABEL: define i32 @length32(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb3:
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX2-LABEL: define i32 @length32(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb3:
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-MIC-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    ret i32 [[PHI_RES]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length32(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb3:
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-MIC-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    ret i32 [[PHI_RES]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       loadbb3:








; X64-SSE2:       endblock:


  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 32) nounwind
  ret i32 %m
}

; PR33325 - https://bugs.llvm.org/show_bug.cgi?id=33325

define i1 @length32_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length32_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length32_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length32_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length32_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length32_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length32_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length32_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length32_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length32_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length32_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512-LABEL: length32_eq:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vpxor (%rsi), %ymm0, %ymm0
; X64-AVX512-NEXT:    vptest %ymm0, %ymm0
; X64-AVX512-NEXT:    sete %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
; X64-MIC-AVX-LABEL: length32_eq:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %ymm0
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %ymm1
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; X64-MIC-AVX-NEXT:    kortestw %k0, %k0
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 32) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length32_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length32_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64:       loadbb3:
; X64-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length32_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb3:
; X64-SSE41-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-SSE41-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-SSE41-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-SSE41-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-SSE41-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-SSE41-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-SSE41-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-SSE41-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length32_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb3:
; X64-AVX1-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX1-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX1-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX1-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX1-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX1-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX1-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX1-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length32_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb3:
; X64-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length32_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb3:
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512BW-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length32_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb3:
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512BW-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length32_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb3:
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512F-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length32_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb3:
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length32_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb3:
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-MIC-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length32_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb3:
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-MIC-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       loadbb3:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 32) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length32_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length32_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    br label [[LOADBB:%.*]]
; X64:       res_block:
; X64-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-NEXT:    br label [[ENDBLOCK:%.*]]
; X64:       loadbb:
; X64-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64:       loadbb1:
; X64-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64:       loadbb2:
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64:       loadbb3:
; X64-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64:       endblock:
; X64-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length32_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    br label [[LOADBB:%.*]]
; X64-SSE41:       res_block:
; X64-SSE41-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-SSE41-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-SSE41-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-SSE41-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-SSE41-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-SSE41:       loadbb:
; X64-SSE41-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-SSE41-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-SSE41-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-SSE41:       loadbb1:
; X64-SSE41-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-SSE41-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-SSE41-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb2:
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-SSE41-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-SSE41-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-SSE41-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-SSE41:       loadbb3:
; X64-SSE41-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-SSE41-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-SSE41-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-SSE41-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-SSE41-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-SSE41-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-SSE41-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-SSE41-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-SSE41:       endblock:
; X64-SSE41-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length32_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX1:       res_block:
; X64-AVX1-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX1-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX1-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX1-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX1-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX1:       loadbb:
; X64-AVX1-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX1-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX1-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX1:       loadbb1:
; X64-AVX1-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX1-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX1-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb2:
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX1-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX1-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX1-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX1:       loadbb3:
; X64-AVX1-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX1-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX1-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX1-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX1-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX1-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX1-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX1-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX1:       endblock:
; X64-AVX1-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length32_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX2:       res_block:
; X64-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX2:       loadbb:
; X64-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX2:       loadbb1:
; X64-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb2:
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX2:       loadbb3:
; X64-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX2:       endblock:
; X64-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length32_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW-256:       res_block:
; X64-AVX512BW-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW-256:       loadbb:
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW-256:       loadbb1:
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb2:
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       loadbb3:
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512BW-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW-256:       endblock:
; X64-AVX512BW-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length32_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512BW:       res_block:
; X64-AVX512BW-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512BW-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512BW-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512BW:       loadbb:
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512BW-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512BW:       loadbb1:
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512BW-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512BW-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb2:
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512BW-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512BW-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512BW:       loadbb3:
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512BW-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512BW-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512BW-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512BW-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512BW-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512BW-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512BW:       endblock:
; X64-AVX512BW-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length32_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F-256:       res_block:
; X64-AVX512F-256-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-256-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-256-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F-256:       loadbb:
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-256-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F-256:       loadbb1:
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-256-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb2:
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-256-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-256-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F-256:       loadbb3:
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512F-256-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-256-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-256-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-256-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-256-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-256-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F-256:       endblock:
; X64-AVX512F-256-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length32_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-AVX512F:       res_block:
; X64-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-AVX512F:       loadbb:
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-AVX512F:       loadbb1:
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb2:
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-AVX512F:       loadbb3:
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-AVX512F:       endblock:
; X64-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length32_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX2:       res_block:
; X64-MIC-AVX2-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX2-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX2-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX2:       loadbb:
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX2-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX2:       loadbb1:
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX2-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb2:
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX2-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       loadbb3:
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-MIC-AVX2-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX2-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX2-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX2-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX2:       endblock:
; X64-MIC-AVX2-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length32_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    br label [[LOADBB:%.*]]
; X64-MIC-AVX512F:       res_block:
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC1:%.*]] = phi i64 [ [[TMP5:%.*]], [[LOADBB]] ], [ [[TMP12:%.*]], [[LOADBB1:%.*]] ], [ [[TMP19:%.*]], [[LOADBB2:%.*]] ], [ [[TMP26:%.*]], [[LOADBB3:%.*]] ]
; X64-MIC-AVX512F-NEXT:    [[PHI_SRC2:%.*]] = phi i64 [ [[TMP6:%.*]], [[LOADBB]] ], [ [[TMP13:%.*]], [[LOADBB1]] ], [ [[TMP20:%.*]], [[LOADBB2]] ], [ [[TMP27:%.*]], [[LOADBB3]] ]
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[PHI_SRC1]], [[PHI_SRC2]]
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = select i1 [[TMP1]], i32 -1, i32 1
; X64-MIC-AVX512F-NEXT:    br label [[ENDBLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb:
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = load i64, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i64, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5]] = call i64 @llvm.bswap.i64(i64 [[TMP3]])
; X64-MIC-AVX512F-NEXT:    [[TMP6]] = call i64 @llvm.bswap.i64(i64 [[TMP4]])
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP7]], label [[LOADBB1]], label [[RES_BLOCK:%.*]]
; X64-MIC-AVX512F:       loadbb1:
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[Y]], i64 8
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i64, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i64, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12]] = call i64 @llvm.bswap.i64(i64 [[TMP10]])
; X64-MIC-AVX512F-NEXT:    [[TMP13]] = call i64 @llvm.bswap.i64(i64 [[TMP11]])
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP14]], label [[LOADBB2]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb2:
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i64, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = load i64, ptr [[TMP16]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP19]] = call i64 @llvm.bswap.i64(i64 [[TMP17]])
; X64-MIC-AVX512F-NEXT:    [[TMP20]] = call i64 @llvm.bswap.i64(i64 [[TMP18]])
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = icmp eq i64 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP21]], label [[LOADBB3]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       loadbb3:
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = getelementptr i8, ptr [[X]], i64 24
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr [[Y]], i64 24
; X64-MIC-AVX512F-NEXT:    [[TMP24:%.*]] = load i64, ptr [[TMP22]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP25:%.*]] = load i64, ptr [[TMP23]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP26]] = call i64 @llvm.bswap.i64(i64 [[TMP24]])
; X64-MIC-AVX512F-NEXT:    [[TMP27]] = call i64 @llvm.bswap.i64(i64 [[TMP25]])
; X64-MIC-AVX512F-NEXT:    [[TMP28:%.*]] = icmp eq i64 [[TMP26]], [[TMP27]]
; X64-MIC-AVX512F-NEXT:    br i1 [[TMP28]], label [[ENDBLOCK]], label [[RES_BLOCK]]
; X64-MIC-AVX512F:       endblock:
; X64-MIC-AVX512F-NEXT:    [[PHI_RES:%.*]] = phi i32 [ 0, [[LOADBB3]] ], [ [[TMP2]], [[RES_BLOCK]] ]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[PHI_RES]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;



; X64-SSE2:       res_block:





; X64-SSE2:       loadbb:






; X64-SSE2:       loadbb1:








; X64-SSE2:       loadbb2:








; X64-SSE2:       loadbb3:








; X64-SSE2:       endblock:



  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 32) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length32_eq_prefer128(ptr %x, ptr %y) nounwind "prefer-vector-width"="128" {
;
; X64-LABEL: define i1 @length32_eq_prefer128(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length32_eq_prefer128(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-SSE41-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length32_eq_prefer128(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length32_eq_prefer128(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length32_eq_prefer128(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length32_eq_prefer128(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length32_eq_prefer128(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length32_eq_prefer128(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length32_eq_prefer128(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length32_eq_prefer128(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i128 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX-LABEL: length32_eq_prefer128:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovdqu 16(%rdi), %xmm1
; X64-AVX-NEXT:    vpxor 16(%rsi), %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    sete %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length32_eq_prefer128:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu 16(%rdi), %xmm1
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %xmm2
; X64-MIC-AVX-NEXT:    vmovdqu 16(%rsi), %xmm3
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 32) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length32_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length32_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-NEXT:    ret i1 [[TMP7]]
;
; X64-SSE41-LABEL: define i1 @length32_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-SSE41-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-SSE41-NEXT:    [[TMP6:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-SSE41-NEXT:    [[TMP7:%.*]] = icmp ne i128 [[TMP6]], 0
; X64-SSE41-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP7]]
;
; X64-AVX1-LABEL: define i1 @length32_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX2-LABEL: define i1 @length32_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512BW-256-LABEL: define i1 @length32_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512BW-LABEL: define i1 @length32_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512F-256-LABEL: define i1 @length32_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512F-LABEL: define i1 @length32_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP2]]
;
; X64-MIC-AVX2-LABEL: define i1 @length32_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP2]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length32_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = icmp ne i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = zext i1 [[TMP2]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP2]]
;
; X64-AVX512-LABEL: length32_eq_const:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0, %ymm0
; X64-AVX512-NEXT:    vptest %ymm0, %ymm0
; X64-AVX512-NEXT:    setne %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
; X64-MIC-AVX-LABEL: length32_eq_const:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %ymm0
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} ymm1 = [858927408,926299444,825243960,892613426,959985462,858927408,926299444,825243960]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k0
; X64-MIC-AVX-NEXT:    kortestw %k0, %k0
; X64-MIC-AVX-NEXT:    setne %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 32) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i32 @length48(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length48(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length48(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length48(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length48(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length48(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length48(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length48(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length48(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length48(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length48(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5:[0-9]+]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 48) nounwind
  ret i32 %m
}

define i1 @length48_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length48_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length48_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-SSE41-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-SSE41-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-SSE41-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-SSE41-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length48_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-AVX1-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-AVX1-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-AVX1-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length48_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-AVX2-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length48_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length48_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length48_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length48_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length48_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length48_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i128 [[TMP6]] to i256
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i128 [[TMP7]] to i256
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i256 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i256 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i256 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP13]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512-LABEL: length48_eq:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vmovdqu 32(%rdi), %xmm1
; X64-AVX512-NEXT:    vmovdqu 32(%rsi), %xmm2
; X64-AVX512-NEXT:    vpxor (%rsi), %ymm0, %ymm0
; X64-AVX512-NEXT:    vpxor %ymm2, %ymm1, %ymm1
; X64-AVX512-NEXT:    vpor %ymm1, %ymm0, %ymm0
; X64-AVX512-NEXT:    vptest %ymm0, %ymm0
; X64-AVX512-NEXT:    sete %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
; X64-MIC-AVX-LABEL: length48_eq:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %ymm0
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %ymm1
; X64-MIC-AVX-NEXT:    vmovdqu 32(%rdi), %xmm2
; X64-MIC-AVX-NEXT:    vmovdqu 32(%rsi), %xmm3
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm2, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 48) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length48_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length48_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length48_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length48_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length48_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length48_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length48_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length48_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length48_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length48_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length48_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 48) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length48_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length48_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length48_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length48_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length48_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length48_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length48_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length48_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length48_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length48_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length48_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 48) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 48) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length48_eq_prefer128(ptr %x, ptr %y) nounwind "prefer-vector-width"="128" {
;
; X64-LABEL: define i1 @length48_eq_prefer128(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length48_eq_prefer128(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-SSE41-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-SSE41-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-SSE41-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-SSE41-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length48_eq_prefer128(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-AVX1-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-AVX1-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-AVX1-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-AVX1-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length48_eq_prefer128(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-AVX2-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-AVX2-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-AVX2-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-AVX2-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length48_eq_prefer128(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length48_eq_prefer128(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length48_eq_prefer128(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length48_eq_prefer128(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length48_eq_prefer128(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length48_eq_prefer128(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR2]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = or i128 [[TMP14]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = icmp ne i128 [[TMP15]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp eq i32 [[TMP17]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-AVX-LABEL: length48_eq_prefer128:
; X64-AVX:       # %bb.0:
; X64-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-AVX-NEXT:    vmovdqu 16(%rdi), %xmm1
; X64-AVX-NEXT:    vmovdqu 32(%rdi), %xmm2
; X64-AVX-NEXT:    vpxor 16(%rsi), %xmm1, %xmm1
; X64-AVX-NEXT:    vpxor (%rsi), %xmm0, %xmm0
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vpxor 32(%rsi), %xmm2, %xmm1
; X64-AVX-NEXT:    vpor %xmm1, %xmm0, %xmm0
; X64-AVX-NEXT:    vptest %xmm0, %xmm0
; X64-AVX-NEXT:    sete %al
; X64-AVX-NEXT:    retq
; X64-MIC-AVX-LABEL: length48_eq_prefer128:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %xmm0
; X64-MIC-AVX-NEXT:    vmovdqu 16(%rdi), %xmm1
; X64-MIC-AVX-NEXT:    vmovdqu 32(%rdi), %xmm2
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %xmm3
; X64-MIC-AVX-NEXT:    vmovdqu 16(%rsi), %xmm4
; X64-MIC-AVX-NEXT:    vmovdqu 32(%rsi), %xmm5
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm4, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm0, %k1
; X64-MIC-AVX-NEXT:    korw %k0, %k1, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm5, %zmm2, %k1
; X64-MIC-AVX-NEXT:    kortestw %k1, %k0
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 48) nounwind
  %cmp = icmp eq i32 %call, 0
  ret i1 %cmp
}

define i1 @length48_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length48_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP6]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP7]], 73389002901949112059321871464991568690
; X64-NEXT:    [[TMP9:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-NEXT:    [[TMP10:%.*]] = or i128 [[TMP9]], [[TMP8]]
; X64-NEXT:    [[TMP11:%.*]] = icmp ne i128 [[TMP10]], 0
; X64-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-NEXT:    ret i1 [[TMP11]]
;
; X64-SSE41-LABEL: define i1 @length48_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-SSE41-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-SSE41-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP6]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP7]], 73389002901949112059321871464991568690
; X64-SSE41-NEXT:    [[TMP9:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-SSE41-NEXT:    [[TMP10:%.*]] = or i128 [[TMP9]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP11:%.*]] = icmp ne i128 [[TMP10]], 0
; X64-SSE41-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP11]]
;
; X64-AVX1-LABEL: define i1 @length48_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-AVX1-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-AVX1-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-AVX1-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-AVX1-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX2-LABEL: define i1 @length48_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-AVX2-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-AVX2-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-AVX2-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-AVX2-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512BW-256-LABEL: define i1 @length48_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512BW-LABEL: define i1 @length48_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512F-256-LABEL: define i1 @length48_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512F-LABEL: define i1 @length48_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP8]]
;
; X64-MIC-AVX2-LABEL: define i1 @length48_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP8]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length48_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = zext i128 [[TMP4]] to i256
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = xor i256 [[TMP5]], 73389002901949112059321871464991568690
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = or i256 [[TMP2]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = icmp ne i256 [[TMP7]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i1 [[TMP8]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP8]]
;
; X64-AVX512-LABEL: length48_eq_const:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vmovdqu 32(%rdi), %xmm1
; X64-AVX512-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0, %ymm0
; X64-AVX512-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm1, %ymm1
; X64-AVX512-NEXT:    vpor %ymm1, %ymm0, %ymm0
; X64-AVX512-NEXT:    vptest %ymm0, %ymm0
; X64-AVX512-NEXT:    setne %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
; X64-MIC-AVX-LABEL: length48_eq_const:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %ymm0
; X64-MIC-AVX-NEXT:    vmovdqu 32(%rdi), %xmm1
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} ymm2 = [892613426,959985462,858927408,926299444,0,0,0,0]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} ymm1 = [858927408,926299444,825243960,892613426,959985462,858927408,926299444,825243960]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    setne %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 48) nounwind
  %c = icmp ne i32 %m, 0
  ret i1 %c
}

define i32 @length63(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length63(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length63(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length63(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length63(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length63(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length63(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length63(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length63(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length63(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length63(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 63) nounwind
  ret i32 %m
}

define i1 @length63_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length63_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 47
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 47
; X64-NEXT:    [[TMP16:%.*]] = load i128, ptr [[TMP14]], align 1
; X64-NEXT:    [[TMP17:%.*]] = load i128, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = xor i128 [[TMP16]], [[TMP17]]
; X64-NEXT:    [[TMP19:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP20:%.*]] = or i128 [[TMP13]], [[TMP18]]
; X64-NEXT:    [[TMP21:%.*]] = or i128 [[TMP19]], [[TMP20]]
; X64-NEXT:    [[TMP22:%.*]] = icmp ne i128 [[TMP21]], 0
; X64-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-NEXT:    ret i1 [[TMP22]]
;
; X64-SSE41-LABEL: define i1 @length63_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-SSE41-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-SSE41-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 47
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 47
; X64-SSE41-NEXT:    [[TMP16:%.*]] = load i128, ptr [[TMP14]], align 1
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i128, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = xor i128 [[TMP16]], [[TMP17]]
; X64-SSE41-NEXT:    [[TMP19:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP20:%.*]] = or i128 [[TMP13]], [[TMP18]]
; X64-SSE41-NEXT:    [[TMP21:%.*]] = or i128 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    [[TMP22:%.*]] = icmp ne i128 [[TMP21]], 0
; X64-SSE41-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX1-LABEL: define i1 @length63_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX2-LABEL: define i1 @length63_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512BW-256-LABEL: define i1 @length63_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512BW-LABEL: define i1 @length63_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-256-LABEL: define i1 @length63_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-LABEL: define i1 @length63_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX2-LABEL: define i1 @length63_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length63_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 31
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512-LABEL: length63_eq:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vmovdqu 31(%rdi), %ymm1
; X64-AVX512-NEXT:    vpxor 31(%rsi), %ymm1, %ymm1
; X64-AVX512-NEXT:    vpxor (%rsi), %ymm0, %ymm0
; X64-AVX512-NEXT:    vpor %ymm1, %ymm0, %ymm0
; X64-AVX512-NEXT:    vptest %ymm0, %ymm0
; X64-AVX512-NEXT:    setne %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
; X64-MIC-AVX-LABEL: length63_eq:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %ymm0
; X64-MIC-AVX-NEXT:    vmovdqu 31(%rdi), %ymm1
; X64-MIC-AVX-NEXT:    vmovdqu (%rsi), %ymm2
; X64-MIC-AVX-NEXT:    vmovdqu 31(%rsi), %ymm3
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm3, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    setne %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 63) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length63_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length63_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length63_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length63_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length63_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length63_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length63_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length63_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length63_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length63_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length63_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 63) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length63_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length63_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length63_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length63_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length63_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length63_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length63_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length63_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length63_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length63_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length63_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 63) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 63) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length63_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length63_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP6]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP7]], 73389002901949112059321871464991568690
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 47
; X64-NEXT:    [[TMP10:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP11:%.*]] = xor i128 [[TMP10]], 66716800424378146251538984255488604215
; X64-NEXT:    [[TMP12:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-NEXT:    [[TMP13:%.*]] = or i128 [[TMP8]], [[TMP11]]
; X64-NEXT:    [[TMP14:%.*]] = or i128 [[TMP12]], [[TMP13]]
; X64-NEXT:    [[TMP15:%.*]] = icmp ne i128 [[TMP14]], 0
; X64-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length63_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-SSE41-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-SSE41-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP6]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP7]], 73389002901949112059321871464991568690
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 47
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = xor i128 [[TMP10]], 66716800424378146251538984255488604215
; X64-SSE41-NEXT:    [[TMP12:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-SSE41-NEXT:    [[TMP13:%.*]] = or i128 [[TMP8]], [[TMP11]]
; X64-SSE41-NEXT:    [[TMP14:%.*]] = or i128 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    [[TMP15:%.*]] = icmp ne i128 [[TMP14]], 0
; X64-SSE41-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length63_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-AVX1-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length63_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-AVX2-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length63_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length63_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length63_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length63_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length63_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length63_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 31
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 22702550761799267355187145649125784605216755694630776232256222584591002841649
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-AVX512-LABEL: length63_eq_const:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu (%rdi), %ymm0
; X64-AVX512-NEXT:    vmovdqu 31(%rdi), %ymm1
; X64-AVX512-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm1, %ymm1
; X64-AVX512-NEXT:    vpxor {{\.?LCPI[0-9]+_[0-9]+}}(%rip), %ymm0, %ymm0
; X64-AVX512-NEXT:    vpor %ymm1, %ymm0, %ymm0
; X64-AVX512-NEXT:    vptest %ymm0, %ymm0
; X64-AVX512-NEXT:    sete %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
; X64-MIC-AVX-LABEL: length63_eq_const:
; X64-MIC-AVX:       # %bb.0:
; X64-MIC-AVX-NEXT:    vmovdqu (%rdi), %ymm0
; X64-MIC-AVX-NEXT:    vmovdqu 31(%rdi), %ymm1
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} ymm2 = [875770417,943142453,842084409,909456435,809056311,875770417,943142453,842084409]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm2, %zmm1, %k0
; X64-MIC-AVX-NEXT:    vmovdqa {{.*#+}} ymm1 = [858927408,926299444,825243960,892613426,959985462,858927408,926299444,825243960]
; X64-MIC-AVX-NEXT:    vpcmpneqd %zmm1, %zmm0, %k1
; X64-MIC-AVX-NEXT:    kortestw %k0, %k1
; X64-MIC-AVX-NEXT:    sete %al
; X64-MIC-AVX-NEXT:    vzeroupper
; X64-MIC-AVX-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 63) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length64(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length64(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length64(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length64(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length64(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length64(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length64(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length64(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length64(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length64(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length64(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 64) nounwind
  ret i32 %m
}

define i1 @length64_eq(ptr %x, ptr %y) nounwind {
;
; X64-LABEL: define i1 @length64_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 48
; X64-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 48
; X64-NEXT:    [[TMP16:%.*]] = load i128, ptr [[TMP14]], align 1
; X64-NEXT:    [[TMP17:%.*]] = load i128, ptr [[TMP15]], align 1
; X64-NEXT:    [[TMP18:%.*]] = xor i128 [[TMP16]], [[TMP17]]
; X64-NEXT:    [[TMP19:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-NEXT:    [[TMP20:%.*]] = or i128 [[TMP13]], [[TMP18]]
; X64-NEXT:    [[TMP21:%.*]] = or i128 [[TMP19]], [[TMP20]]
; X64-NEXT:    [[TMP22:%.*]] = icmp ne i128 [[TMP21]], 0
; X64-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-NEXT:    ret i1 [[TMP22]]
;
; X64-SSE41-LABEL: define i1 @length64_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = load i128, ptr [[Y]], align 1
; X64-SSE41-NEXT:    [[TMP3:%.*]] = xor i128 [[TMP1]], [[TMP2]]
; X64-SSE41-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 16
; X64-SSE41-NEXT:    [[TMP6:%.*]] = load i128, ptr [[TMP4]], align 1
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP5]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP6]], [[TMP7]]
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-SSE41-NEXT:    [[TMP11:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP12:%.*]] = load i128, ptr [[TMP10]], align 1
; X64-SSE41-NEXT:    [[TMP13:%.*]] = xor i128 [[TMP11]], [[TMP12]]
; X64-SSE41-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 48
; X64-SSE41-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 48
; X64-SSE41-NEXT:    [[TMP16:%.*]] = load i128, ptr [[TMP14]], align 1
; X64-SSE41-NEXT:    [[TMP17:%.*]] = load i128, ptr [[TMP15]], align 1
; X64-SSE41-NEXT:    [[TMP18:%.*]] = xor i128 [[TMP16]], [[TMP17]]
; X64-SSE41-NEXT:    [[TMP19:%.*]] = or i128 [[TMP3]], [[TMP8]]
; X64-SSE41-NEXT:    [[TMP20:%.*]] = or i128 [[TMP13]], [[TMP18]]
; X64-SSE41-NEXT:    [[TMP21:%.*]] = or i128 [[TMP19]], [[TMP20]]
; X64-SSE41-NEXT:    [[TMP22:%.*]] = icmp ne i128 [[TMP21]], 0
; X64-SSE41-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-SSE41-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX1-LABEL: define i1 @length64_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX1-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX2-LABEL: define i1 @length64_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512BW-256-LABEL: define i1 @length64_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512BW-LABEL: define i1 @length64_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512F-256-LABEL: define i1 @length64_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-LABEL: define i1 @length64_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP3]]
;
; X64-MIC-AVX2-LABEL: define i1 @length64_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = icmp ne i256 [[TMP9]], 0
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length64_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP3]]
;
; X64-AVX512-LABEL: length64_eq:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu64 (%rdi), %zmm0
; X64-AVX512-NEXT:    vpcmpneqd (%rsi), %zmm0, %k0
; X64-AVX512-NEXT:    kortestw %k0, %k0
; X64-AVX512-NEXT:    setne %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 64) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length64_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length64_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length64_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length64_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length64_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length64_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length64_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length64_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length64_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length64_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length64_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 64) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length64_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length64_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length64_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length64_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length64_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length64_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length64_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length64_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length64_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length64_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length64_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 64) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 64) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length64_eq_const(ptr %X) nounwind {
;
; X64-LABEL: define i1 @length64_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP6]], align 1
; X64-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP7]], 73389002901949112059321871464991568690
; X64-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 48
; X64-NEXT:    [[TMP10:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-NEXT:    [[TMP11:%.*]] = xor i128 [[TMP10]], 68051240286688436651889234231545575736
; X64-NEXT:    [[TMP12:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-NEXT:    [[TMP13:%.*]] = or i128 [[TMP8]], [[TMP11]]
; X64-NEXT:    [[TMP14:%.*]] = or i128 [[TMP12]], [[TMP13]]
; X64-NEXT:    [[TMP15:%.*]] = icmp ne i128 [[TMP14]], 0
; X64-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length64_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[TMP1:%.*]] = load i128, ptr [[X]], align 1
; X64-SSE41-NEXT:    [[TMP2:%.*]] = xor i128 [[TMP1]], 70720121592765328381466889075544961328
; X64-SSE41-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 16
; X64-SSE41-NEXT:    [[TMP4:%.*]] = load i128, ptr [[TMP3]], align 1
; X64-SSE41-NEXT:    [[TMP5:%.*]] = xor i128 [[TMP4]], 65382562593882267225249597816672106294
; X64-SSE41-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-SSE41-NEXT:    [[TMP7:%.*]] = load i128, ptr [[TMP6]], align 1
; X64-SSE41-NEXT:    [[TMP8:%.*]] = xor i128 [[TMP7]], 73389002901949112059321871464991568690
; X64-SSE41-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 48
; X64-SSE41-NEXT:    [[TMP10:%.*]] = load i128, ptr [[TMP9]], align 1
; X64-SSE41-NEXT:    [[TMP11:%.*]] = xor i128 [[TMP10]], 68051240286688436651889234231545575736
; X64-SSE41-NEXT:    [[TMP12:%.*]] = or i128 [[TMP2]], [[TMP5]]
; X64-SSE41-NEXT:    [[TMP13:%.*]] = or i128 [[TMP8]], [[TMP11]]
; X64-SSE41-NEXT:    [[TMP14:%.*]] = or i128 [[TMP12]], [[TMP13]]
; X64-SSE41-NEXT:    [[TMP15:%.*]] = icmp ne i128 [[TMP14]], 0
; X64-SSE41-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length64_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX1-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX1-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX1-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length64_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX2-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX2-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length64_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length64_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = icmp ne i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length64_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length64_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length64_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = icmp ne i256 [[TMP6]], 0
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = zext i1 [[TMP7]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP8]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length64_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = icmp ne i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = zext i1 [[TMP3]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP4]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-AVX512-LABEL: length64_eq_const:
; X64-AVX512:       # %bb.0:
; X64-AVX512-NEXT:    vmovdqu64 (%rdi), %zmm0
; X64-AVX512-NEXT:    vpcmpneqd .L.str(%rip), %zmm0, %k0
; X64-AVX512-NEXT:    kortestw %k0, %k0
; X64-AVX512-NEXT:    sete %al
; X64-AVX512-NEXT:    vzeroupper
; X64-AVX512-NEXT:    retq
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 64) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length96(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length96(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length96(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length96(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length96(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length96(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length96(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length96(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length96(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length96(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length96(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 96) nounwind
  ret i32 %m
}

define i1 @length96_eq(ptr %x, ptr %y) nounwind {
; X64-SSE-LABEL: length96_eq:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $96, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    setne %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length96_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length96_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length96_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX1-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX1-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX1-NEXT:    [[TMP14:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP15:%.*]] = or i256 [[TMP14]], [[TMP13]]
; X64-AVX1-NEXT:    [[TMP16:%.*]] = icmp ne i256 [[TMP15]], 0
; X64-AVX1-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP16]]
;
; X64-AVX2-LABEL: define i1 @length96_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX2-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX2-NEXT:    [[TMP14:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP15:%.*]] = or i256 [[TMP14]], [[TMP13]]
; X64-AVX2-NEXT:    [[TMP16:%.*]] = icmp ne i256 [[TMP15]], 0
; X64-AVX2-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP16]]
;
; X64-AVX512BW-256-LABEL: define i1 @length96_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = or i256 [[TMP14]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = icmp ne i256 [[TMP15]], 0
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP16]]
;
; X64-AVX512BW-LABEL: define i1 @length96_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = zext i256 [[TMP6]] to i512
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = zext i256 [[TMP7]] to i512
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = xor i512 [[TMP8]], [[TMP9]]
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = or i512 [[TMP3]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = icmp ne i512 [[TMP11]], 0
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP12]]
;
; X64-AVX512F-256-LABEL: define i1 @length96_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = or i256 [[TMP14]], [[TMP13]]
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = icmp ne i256 [[TMP15]], 0
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP16]]
;
; X64-AVX512F-LABEL: define i1 @length96_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = zext i256 [[TMP6]] to i512
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = zext i256 [[TMP7]] to i512
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = xor i512 [[TMP8]], [[TMP9]]
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = or i512 [[TMP3]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i512 [[TMP11]], 0
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP12]]
;
; X64-MIC-AVX2-LABEL: define i1 @length96_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = or i256 [[TMP14]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = icmp ne i256 [[TMP15]], 0
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP16]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length96_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = zext i256 [[TMP6]] to i512
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = zext i256 [[TMP7]] to i512
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = xor i512 [[TMP8]], [[TMP9]]
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = or i512 [[TMP3]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = icmp ne i512 [[TMP11]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = zext i1 [[TMP12]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP12]]
;
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 96) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length96_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length96_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length96_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length96_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length96_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length96_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length96_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length96_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length96_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length96_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length96_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 96) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length96_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length96_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length96_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length96_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length96_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length96_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length96_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length96_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length96_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length96_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length96_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 96) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 96) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length96_eq_const(ptr %X) nounwind {
; X64-SSE-LABEL: length96_eq_const:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $.L.str, %esi
; X64-SSE-NEXT:    movl $96, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    sete %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length96_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 96) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length96_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 96) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length96_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX1-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX1-NEXT:    [[TMP9:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX1-NEXT:    [[TMP10:%.*]] = or i256 [[TMP9]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP11:%.*]] = icmp ne i256 [[TMP10]], 0
; X64-AVX1-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP12]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length96_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX2-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX2-NEXT:    [[TMP9:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX2-NEXT:    [[TMP10:%.*]] = or i256 [[TMP9]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP11:%.*]] = icmp ne i256 [[TMP10]], 0
; X64-AVX2-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP12]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length96_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = or i256 [[TMP9]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = icmp ne i256 [[TMP10]], 0
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP12]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length96_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = zext i256 [[TMP5]] to i512
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP6]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length96_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = or i256 [[TMP9]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = icmp ne i256 [[TMP10]], 0
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP12]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length96_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = zext i256 [[TMP5]] to i512
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP6]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length96_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = or i256 [[TMP9]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = icmp ne i256 [[TMP10]], 0
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = zext i1 [[TMP11]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP12]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length96_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = zext i256 [[TMP5]] to i512
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP6]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 96) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length127(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length127(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length127(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length127(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length127(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length127(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length127(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length127(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length127(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length127(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length127(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 127) nounwind
  ret i32 %m
}

define i1 @length127_eq(ptr %x, ptr %y) nounwind {
; X64-SSE-LABEL: length127_eq:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $127, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    setne %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length127_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length127_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length127_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX1-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX1-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX1-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 95
; X64-AVX1-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX1-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX1-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX1-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX2-LABEL: define i1 @length127_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX2-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX2-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 95
; X64-AVX2-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX2-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX2-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX2-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512BW-256-LABEL: define i1 @length127_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 95
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX512BW-256-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512BW-LABEL: define i1 @length127_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 63
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 63
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i512 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-256-LABEL: define i1 @length127_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 95
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX512F-256-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512F-LABEL: define i1 @length127_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 63
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 63
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i512 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX2-LABEL: define i1 @length127_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 95
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-MIC-AVX2-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP22]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length127_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 63
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 63
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i512 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP10]]
;
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 127) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length127_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length127_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length127_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length127_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length127_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length127_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length127_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length127_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length127_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length127_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length127_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 127) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length127_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length127_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length127_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length127_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length127_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length127_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length127_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length127_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length127_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length127_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length127_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 127) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 127) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length127_eq_const(ptr %X) nounwind {
; X64-SSE-LABEL: length127_eq_const:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $.L.str, %esi
; X64-SSE-NEXT:    movl $127, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    sete %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length127_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 127) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length127_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 127) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length127_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX1-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24518896988982801982081367250212210778372643504230047123819838724519570650677
; X64-AVX1-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX1-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX1-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX1-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length127_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX2-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24518896988982801982081367250212210778372643504230047123819838724519570650677
; X64-AVX2-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX2-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX2-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX2-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length127_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24518896988982801982081367250212210778372643504230047123819838724519570650677
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length127_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 63
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 63), align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length127_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24518896988982801982081367250212210778372643504230047123819838724519570650677
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length127_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 63
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 63), align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length127_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 95
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24518896988982801982081367250212210778372643504230047123819838724519570650677
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length127_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 63
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 63), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 127) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length128(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length128(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length128(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length128(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length128(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length128(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length128(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length128(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length128(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length128(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length128(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 128) nounwind
  ret i32 %m
}

define i1 @length128_eq(ptr %x, ptr %y) nounwind {
; X64-SSE-LABEL: length128_eq:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $128, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    setne %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length128_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length128_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length128_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX1-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX1-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX1-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX1-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX1-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX1-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX1-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX1-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 96
; X64-AVX1-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX1-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX1-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX1-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX1-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX1-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX1-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX1-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX1-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX2-LABEL: define i1 @length128_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX2-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX2-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX2-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 96
; X64-AVX2-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX2-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX2-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX2-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX2-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX2-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX2-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX2-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX2-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512BW-256-LABEL: define i1 @length128_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 96
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX512BW-256-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512BW-256-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX512BW-256-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX512BW-256-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX512BW-256-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512BW-256-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512BW-LABEL: define i1 @length128_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = icmp ne i512 [[TMP9]], 0
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP10]]
;
; X64-AVX512F-256-LABEL: define i1 @length128_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 96
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-AVX512F-256-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-AVX512F-256-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-AVX512F-256-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-AVX512F-256-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-AVX512F-256-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-AVX512F-256-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-AVX512F-256-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512F-256-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512F-LABEL: define i1 @length128_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i512 [[TMP9]], 0
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP10]]
;
; X64-MIC-AVX2-LABEL: define i1 @length128_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = load i256, ptr [[Y]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = xor i256 [[TMP1]], [[TMP2]]
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = load i256, ptr [[TMP4]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP5]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP6]], [[TMP7]]
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = load i256, ptr [[TMP10]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = xor i256 [[TMP11]], [[TMP12]]
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 96
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = load i256, ptr [[TMP14]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP17:%.*]] = load i256, ptr [[TMP15]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP18:%.*]] = xor i256 [[TMP16]], [[TMP17]]
; X64-MIC-AVX2-NEXT:    [[TMP19:%.*]] = or i256 [[TMP3]], [[TMP8]]
; X64-MIC-AVX2-NEXT:    [[TMP20:%.*]] = or i256 [[TMP13]], [[TMP18]]
; X64-MIC-AVX2-NEXT:    [[TMP21:%.*]] = or i256 [[TMP19]], [[TMP20]]
; X64-MIC-AVX2-NEXT:    [[TMP22:%.*]] = icmp ne i256 [[TMP21]], 0
; X64-MIC-AVX2-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-MIC-AVX2-NEXT:    ret i1 [[TMP22]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length128_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = icmp ne i512 [[TMP9]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = zext i1 [[TMP10]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP10]]
;
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 128) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length128_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length128_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length128_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length128_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length128_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length128_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length128_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length128_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length128_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length128_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length128_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 128) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length128_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length128_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length128_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length128_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length128_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length128_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length128_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length128_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length128_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length128_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length128_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 128) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 128) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length128_eq_const(ptr %X) nounwind {
; X64-SSE-LABEL: length128_eq_const:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $.L.str, %esi
; X64-SSE-NEXT:    movl $128, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    sete %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length128_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 128) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length128_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 128) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length128_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX1-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX1-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX1-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX1-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX1-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX1-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX1-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX1-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX1-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX1-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24972983613442865430775334151281434151203991406697113551929636559217741018934
; X64-AVX1-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX1-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX1-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX1-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX1-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length128_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX2-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX2-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX2-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24972983613442865430775334151281434151203991406697113551929636559217741018934
; X64-AVX2-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX2-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX2-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX2-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX2-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length128_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512BW-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512BW-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512BW-256-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512BW-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX512BW-256-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512BW-256-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24972983613442865430775334151281434151203991406697113551929636559217741018934
; X64-AVX512BW-256-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512BW-256-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX512BW-256-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX512BW-256-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX512BW-256-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length128_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length128_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-AVX512F-256-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-AVX512F-256-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-AVX512F-256-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-AVX512F-256-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-AVX512F-256-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-256-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-AVX512F-256-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-AVX512F-256-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-AVX512F-256-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-AVX512F-256-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24972983613442865430775334151281434151203991406697113551929636559217741018934
; X64-AVX512F-256-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-AVX512F-256-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-AVX512F-256-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-AVX512F-256-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-AVX512F-256-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length128_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length128_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[TMP1:%.*]] = load i256, ptr [[X]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP2:%.*]] = xor i256 [[TMP1]], 22248533154802671749360035741805466271990224543450513484713781259640245465392
; X64-MIC-AVX2-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[X]], i64 32
; X64-MIC-AVX2-NEXT:    [[TMP4:%.*]] = load i256, ptr [[TMP3]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP5:%.*]] = xor i256 [[TMP4]], 23156637116659864195145731957391441738757757709540232586892941433547502400306
; X64-MIC-AVX2-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX2-NEXT:    [[TMP7:%.*]] = load i256, ptr [[TMP6]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP8:%.*]] = xor i256 [[TMP7]], 24064810364522754539996825585178935186817565138301605567169177049701086016820
; X64-MIC-AVX2-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 96
; X64-MIC-AVX2-NEXT:    [[TMP10:%.*]] = load i256, ptr [[TMP9]], align 1
; X64-MIC-AVX2-NEXT:    [[TMP11:%.*]] = xor i256 [[TMP10]], 24972983613442865430775334151281434151203991406697113551929636559217741018934
; X64-MIC-AVX2-NEXT:    [[TMP12:%.*]] = or i256 [[TMP2]], [[TMP5]]
; X64-MIC-AVX2-NEXT:    [[TMP13:%.*]] = or i256 [[TMP8]], [[TMP11]]
; X64-MIC-AVX2-NEXT:    [[TMP14:%.*]] = or i256 [[TMP12]], [[TMP13]]
; X64-MIC-AVX2-NEXT:    [[TMP15:%.*]] = icmp ne i256 [[TMP14]], 0
; X64-MIC-AVX2-NEXT:    [[TMP16:%.*]] = zext i1 [[TMP15]] to i32
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP16]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length128_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = icmp ne i512 [[TMP8]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = zext i1 [[TMP9]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP10]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 128) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length192(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length192(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length192(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length192(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length192(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length192(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length192(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length192(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length192(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length192(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length192(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 192) nounwind
  ret i32 %m
}

define i1 @length192_eq(ptr %x, ptr %y) nounwind {
; X64-SSE-LABEL: length192_eq:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $192, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    setne %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length192_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length192_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length192_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length192_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length192_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length192_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = or i512 [[TMP14]], [[TMP13]]
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = icmp ne i512 [[TMP15]], 0
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP16]]
;
; X64-AVX512F-256-LABEL: define i1 @length192_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length192_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = or i512 [[TMP14]], [[TMP13]]
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = icmp ne i512 [[TMP15]], 0
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP16]]
;
; X64-MIC-AVX2-LABEL: define i1 @length192_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length192_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = or i512 [[TMP14]], [[TMP13]]
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = icmp ne i512 [[TMP15]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = zext i1 [[TMP16]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP16]]
;
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 192) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length192_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length192_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length192_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length192_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length192_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length192_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length192_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length192_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length192_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length192_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length192_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 192) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length192_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length192_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length192_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length192_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length192_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length192_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length192_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length192_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length192_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length192_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length192_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 192) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 192) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length192_eq_const(ptr %X) nounwind {
; X64-SSE-LABEL: length192_eq_const:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $.L.str, %esi
; X64-SSE-NEXT:    movl $192, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    sete %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length192_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length192_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length192_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length192_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length192_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length192_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = or i512 [[TMP12]], [[TMP11]]
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = icmp ne i512 [[TMP13]], 0
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = zext i1 [[TMP14]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP15]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length192_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length192_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = or i512 [[TMP12]], [[TMP11]]
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = icmp ne i512 [[TMP13]], 0
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = zext i1 [[TMP14]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP15]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length192_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 192) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length192_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = or i512 [[TMP12]], [[TMP11]]
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = icmp ne i512 [[TMP13]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = zext i1 [[TMP14]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP15]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 192) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length255(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length255(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length255(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length255(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length255(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length255(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length255(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length255(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length255(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length255(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length255(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 255) nounwind
  ret i32 %m
}

define i1 @length255_eq(ptr %x, ptr %y) nounwind {
; X64-SSE-LABEL: length255_eq:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $255, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    setne %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length255_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length255_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length255_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length255_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length255_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length255_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 191
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 191
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = load i512, ptr [[TMP14]], align 1
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i512, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = xor i512 [[TMP16]], [[TMP17]]
; X64-AVX512BW-NEXT:    [[TMP19:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP20:%.*]] = or i512 [[TMP13]], [[TMP18]]
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = or i512 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = icmp ne i512 [[TMP21]], 0
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512F-256-LABEL: define i1 @length255_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length255_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 191
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 191
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = load i512, ptr [[TMP14]], align 1
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i512, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = xor i512 [[TMP16]], [[TMP17]]
; X64-AVX512F-NEXT:    [[TMP19:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP20:%.*]] = or i512 [[TMP13]], [[TMP18]]
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = or i512 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = icmp ne i512 [[TMP21]], 0
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP22]]
;
; X64-MIC-AVX2-LABEL: define i1 @length255_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length255_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 191
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 191
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = load i512, ptr [[TMP14]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i512, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = xor i512 [[TMP16]], [[TMP17]]
; X64-MIC-AVX512F-NEXT:    [[TMP19:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP20:%.*]] = or i512 [[TMP13]], [[TMP18]]
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = or i512 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = icmp ne i512 [[TMP21]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP22]]
;
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 255) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length255_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length255_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length255_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length255_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length255_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length255_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length255_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length255_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length255_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length255_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length255_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 255) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length255_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length255_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length255_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length255_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length255_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length255_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length255_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length255_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length255_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length255_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length255_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 255) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 255) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length255_eq_const(ptr %X) nounwind {
; X64-SSE-LABEL: length255_eq_const:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $.L.str, %esi
; X64-SSE-NEXT:    movl $255, %edx
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    sete %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length255_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length255_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length255_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length255_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length255_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length255_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 191
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = load i512, ptr [[TMP12]], align 1
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 191), align 1
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = xor i512 [[TMP13]], [[TMP14]]
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = or i512 [[TMP11]], [[TMP15]]
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = or i512 [[TMP16]], [[TMP17]]
; X64-AVX512BW-NEXT:    [[TMP19:%.*]] = icmp ne i512 [[TMP18]], 0
; X64-AVX512BW-NEXT:    [[TMP20:%.*]] = zext i1 [[TMP19]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP20]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length255_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length255_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 191
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = load i512, ptr [[TMP12]], align 1
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 191), align 1
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = xor i512 [[TMP13]], [[TMP14]]
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = or i512 [[TMP11]], [[TMP15]]
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = or i512 [[TMP16]], [[TMP17]]
; X64-AVX512F-NEXT:    [[TMP19:%.*]] = icmp ne i512 [[TMP18]], 0
; X64-AVX512F-NEXT:    [[TMP20:%.*]] = zext i1 [[TMP19]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP20]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length255_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 255) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length255_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 191
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = load i512, ptr [[TMP12]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 191), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = xor i512 [[TMP13]], [[TMP14]]
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = or i512 [[TMP11]], [[TMP15]]
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = or i512 [[TMP16]], [[TMP17]]
; X64-MIC-AVX512F-NEXT:    [[TMP19:%.*]] = icmp ne i512 [[TMP18]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP20:%.*]] = zext i1 [[TMP19]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP20]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 255) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length256(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length256(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length256(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length256(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length256(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length256(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length256(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length256(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length256(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length256(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length256(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 256) nounwind
  ret i32 %m
}

define i1 @length256_eq(ptr %x, ptr %y) nounwind {
; X64-SSE-LABEL: length256_eq:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $256, %edx # imm = 0x100
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    setne %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length256_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length256_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length256_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length256_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length256_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length256_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 192
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 192
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = load i512, ptr [[TMP14]], align 1
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = load i512, ptr [[TMP15]], align 1
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = xor i512 [[TMP16]], [[TMP17]]
; X64-AVX512BW-NEXT:    [[TMP19:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512BW-NEXT:    [[TMP20:%.*]] = or i512 [[TMP13]], [[TMP18]]
; X64-AVX512BW-NEXT:    [[TMP21:%.*]] = or i512 [[TMP19]], [[TMP20]]
; X64-AVX512BW-NEXT:    [[TMP22:%.*]] = icmp ne i512 [[TMP21]], 0
; X64-AVX512BW-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512BW-NEXT:    ret i1 [[TMP22]]
;
; X64-AVX512F-256-LABEL: define i1 @length256_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length256_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 192
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 192
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = load i512, ptr [[TMP14]], align 1
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = load i512, ptr [[TMP15]], align 1
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = xor i512 [[TMP16]], [[TMP17]]
; X64-AVX512F-NEXT:    [[TMP19:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-AVX512F-NEXT:    [[TMP20:%.*]] = or i512 [[TMP13]], [[TMP18]]
; X64-AVX512F-NEXT:    [[TMP21:%.*]] = or i512 [[TMP19]], [[TMP20]]
; X64-AVX512F-NEXT:    [[TMP22:%.*]] = icmp ne i512 [[TMP21]], 0
; X64-AVX512F-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-AVX512F-NEXT:    ret i1 [[TMP22]]
;
; X64-MIC-AVX2-LABEL: define i1 @length256_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length256_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr [[Y]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[Y]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = load i512, ptr [[TMP5]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = xor i512 [[TMP6]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = getelementptr i8, ptr [[Y]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = load i512, ptr [[TMP9]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = load i512, ptr [[TMP10]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = xor i512 [[TMP11]], [[TMP12]]
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr [[X]], i64 192
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr [[Y]], i64 192
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = load i512, ptr [[TMP14]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = load i512, ptr [[TMP15]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = xor i512 [[TMP16]], [[TMP17]]
; X64-MIC-AVX512F-NEXT:    [[TMP19:%.*]] = or i512 [[TMP3]], [[TMP8]]
; X64-MIC-AVX512F-NEXT:    [[TMP20:%.*]] = or i512 [[TMP13]], [[TMP18]]
; X64-MIC-AVX512F-NEXT:    [[TMP21:%.*]] = or i512 [[TMP19]], [[TMP20]]
; X64-MIC-AVX512F-NEXT:    [[TMP22:%.*]] = icmp ne i512 [[TMP21]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP23:%.*]] = zext i1 [[TMP22]] to i32
; X64-MIC-AVX512F-NEXT:    ret i1 [[TMP22]]
;
  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 256) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length256_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length256_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length256_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length256_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length256_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length256_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length256_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length256_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length256_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length256_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length256_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 256) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length256_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length256_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length256_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length256_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length256_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length256_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length256_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length256_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length256_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length256_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length256_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 256) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 256) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length256_eq_const(ptr %X) nounwind {
; X64-SSE-LABEL: length256_eq_const:
; X64-SSE:       # %bb.0:
; X64-SSE-NEXT:    pushq %rax
; X64-SSE-NEXT:    movl $.L.str, %esi
; X64-SSE-NEXT:    movl $256, %edx # imm = 0x100
; X64-SSE-NEXT:    callq memcmp
; X64-SSE-NEXT:    testl %eax, %eax
; X64-SSE-NEXT:    sete %al
; X64-SSE-NEXT:    popq %rcx
; X64-SSE-NEXT:    retq
;
;
; X64-LABEL: define i1 @length256_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length256_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length256_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length256_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length256_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length256_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512BW-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512BW-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512BW-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512BW-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512BW-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512BW-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512BW-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512BW-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-AVX512BW-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-AVX512BW-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-AVX512BW-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 192
; X64-AVX512BW-NEXT:    [[TMP13:%.*]] = load i512, ptr [[TMP12]], align 1
; X64-AVX512BW-NEXT:    [[TMP14:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 192), align 1
; X64-AVX512BW-NEXT:    [[TMP15:%.*]] = xor i512 [[TMP13]], [[TMP14]]
; X64-AVX512BW-NEXT:    [[TMP16:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512BW-NEXT:    [[TMP17:%.*]] = or i512 [[TMP11]], [[TMP15]]
; X64-AVX512BW-NEXT:    [[TMP18:%.*]] = or i512 [[TMP16]], [[TMP17]]
; X64-AVX512BW-NEXT:    [[TMP19:%.*]] = icmp ne i512 [[TMP18]], 0
; X64-AVX512BW-NEXT:    [[TMP20:%.*]] = zext i1 [[TMP19]] to i32
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP20]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length256_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length256_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-AVX512F-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-AVX512F-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-AVX512F-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-AVX512F-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 192
; X64-AVX512F-NEXT:    [[TMP13:%.*]] = load i512, ptr [[TMP12]], align 1
; X64-AVX512F-NEXT:    [[TMP14:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 192), align 1
; X64-AVX512F-NEXT:    [[TMP15:%.*]] = xor i512 [[TMP13]], [[TMP14]]
; X64-AVX512F-NEXT:    [[TMP16:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-AVX512F-NEXT:    [[TMP17:%.*]] = or i512 [[TMP11]], [[TMP15]]
; X64-AVX512F-NEXT:    [[TMP18:%.*]] = or i512 [[TMP16]], [[TMP17]]
; X64-AVX512F-NEXT:    [[TMP19:%.*]] = icmp ne i512 [[TMP18]], 0
; X64-AVX512F-NEXT:    [[TMP20:%.*]] = zext i1 [[TMP19]] to i32
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP20]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length256_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 256) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length256_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[TMP1:%.*]] = load i512, ptr [[X]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP2:%.*]] = load i512, ptr @.str, align 1
; X64-MIC-AVX512F-NEXT:    [[TMP3:%.*]] = xor i512 [[TMP1]], [[TMP2]]
; X64-MIC-AVX512F-NEXT:    [[TMP4:%.*]] = getelementptr i8, ptr [[X]], i64 64
; X64-MIC-AVX512F-NEXT:    [[TMP5:%.*]] = load i512, ptr [[TMP4]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP6:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 64), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP7:%.*]] = xor i512 [[TMP5]], [[TMP6]]
; X64-MIC-AVX512F-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[X]], i64 128
; X64-MIC-AVX512F-NEXT:    [[TMP9:%.*]] = load i512, ptr [[TMP8]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP10:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 128), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP11:%.*]] = xor i512 [[TMP9]], [[TMP10]]
; X64-MIC-AVX512F-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr [[X]], i64 192
; X64-MIC-AVX512F-NEXT:    [[TMP13:%.*]] = load i512, ptr [[TMP12]], align 1
; X64-MIC-AVX512F-NEXT:    [[TMP14:%.*]] = load i512, ptr getelementptr (i8, ptr @.str, i64 192), align 1
; X64-MIC-AVX512F-NEXT:    [[TMP15:%.*]] = xor i512 [[TMP13]], [[TMP14]]
; X64-MIC-AVX512F-NEXT:    [[TMP16:%.*]] = or i512 [[TMP3]], [[TMP7]]
; X64-MIC-AVX512F-NEXT:    [[TMP17:%.*]] = or i512 [[TMP11]], [[TMP15]]
; X64-MIC-AVX512F-NEXT:    [[TMP18:%.*]] = or i512 [[TMP16]], [[TMP17]]
; X64-MIC-AVX512F-NEXT:    [[TMP19:%.*]] = icmp ne i512 [[TMP18]], 0
; X64-MIC-AVX512F-NEXT:    [[TMP20:%.*]] = zext i1 [[TMP19]] to i32
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[TMP20]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;
  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 256) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length384(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length384(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length384(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length384(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length384(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length384(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length384(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length384(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length384(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length384(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length384(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 384) nounwind
  ret i32 %m
}

define i1 @length384_eq(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length384_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length384_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length384_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length384_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length384_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length384_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length384_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length384_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length384_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length384_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 384) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length384_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length384_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length384_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length384_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length384_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length384_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length384_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length384_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length384_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length384_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length384_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 384) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length384_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length384_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length384_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length384_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length384_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length384_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length384_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length384_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length384_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length384_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length384_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 384) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 384) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length384_eq_const(ptr %X) nounwind {
; X64-LABEL: define i1 @length384_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length384_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length384_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length384_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length384_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length384_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length384_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length384_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length384_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length384_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 384) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;





  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 384) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length511(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length511(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length511(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length511(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length511(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length511(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length511(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length511(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length511(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length511(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length511(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 511) nounwind
  ret i32 %m
}

define i1 @length511_eq(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length511_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length511_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length511_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length511_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length511_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length511_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length511_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length511_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length511_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length511_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 511) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length511_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length511_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length511_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length511_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length511_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length511_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length511_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length511_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length511_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length511_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length511_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 511) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length511_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length511_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length511_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length511_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length511_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length511_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length511_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length511_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length511_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length511_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length511_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 511) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 511) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length511_eq_const(ptr %X) nounwind {
; X64-LABEL: define i1 @length511_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length511_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length511_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length511_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length511_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length511_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length511_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length511_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length511_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length511_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 511) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;





  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 511) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

define i32 @length512(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @length512(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @length512(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @length512(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @length512(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @length512(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @length512(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @length512(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @length512(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @length512(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @length512(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 512) nounwind
  ret i32 %m
}

define i1 @length512_eq(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length512_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length512_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length512_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length512_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length512_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length512_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length512_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length512_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length512_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length512_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp ne i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 512) nounwind
  %cmp = icmp ne i32 %call, 0
  ret i1 %cmp
}

define i1 @length512_lt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length512_lt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length512_lt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length512_lt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length512_lt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length512_lt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length512_lt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length512_lt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length512_lt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length512_lt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length512_lt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp slt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 512) nounwind
  %cmp = icmp slt i32 %call, 0
  ret i1 %cmp
}

define i1 @length512_gt(ptr %x, ptr %y) nounwind {
; X64-LABEL: define i1 @length512_gt(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR0]]
; X64-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-NEXT:    ret i1 [[CMP]]
;
; X64-SSE41-LABEL: define i1 @length512_gt(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-SSE41-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-SSE41-NEXT:    ret i1 [[CMP]]
;
; X64-AVX1-LABEL: define i1 @length512_gt(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX1-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX1-NEXT:    ret i1 [[CMP]]
;
; X64-AVX2-LABEL: define i1 @length512_gt(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-256-LABEL: define i1 @length512_gt(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512BW-LABEL: define i1 @length512_gt(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512BW-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-256-LABEL: define i1 @length512_gt(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[CMP]]
;
; X64-AVX512F-LABEL: define i1 @length512_gt(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-AVX512F-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX2-LABEL: define i1 @length512_gt(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[CMP]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length512_gt(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[CALL:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 512) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[CMP:%.*]] = icmp sgt i32 [[CALL]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[CMP]]
;





  %call = tail call i32 @memcmp(ptr %x, ptr %y, i64 512) nounwind
  %cmp = icmp sgt i32 %call, 0
  ret i1 %cmp
}

define i1 @length512_eq_const(ptr %X) nounwind {
; X64-LABEL: define i1 @length512_eq_const(
; X64-SAME: ptr [[X:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @length512_eq_const(
; X64-SSE41-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @length512_eq_const(
; X64-AVX1-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @length512_eq_const(
; X64-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @length512_eq_const(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @length512_eq_const(
; X64-AVX512BW-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @length512_eq_const(
; X64-AVX512F-256-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @length512_eq_const(
; X64-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @length512_eq_const(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @length512_eq_const(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr @.str, i64 512) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;





  %m = tail call i32 @memcmp(ptr %X, ptr @.str, i64 512) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

; This checks that we do not do stupid things with huge sizes.
define i32 @huge_length(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i32 @huge_length(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @huge_length(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @huge_length(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @huge_length(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @huge_length(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @huge_length(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @huge_length(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @huge_length(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @huge_length(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @huge_length(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 9223372036854775807) nounwind
  ret i32 %m
}

define i1 @huge_length_eq(ptr %X, ptr %Y) nounwind {
; X64-LABEL: define i1 @huge_length_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @huge_length_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @huge_length_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @huge_length_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @huge_length_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @huge_length_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @huge_length_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @huge_length_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @huge_length_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @huge_length_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 9223372036854775807) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;





  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 9223372036854775807) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}

; This checks non-constant sizes.
define i32 @nonconst_length(ptr %X, ptr %Y, i64 %size) nounwind {
; X64-LABEL: define i32 @nonconst_length(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR0]]
; X64-NEXT:    ret i32 [[M]]
;
; X64-SSE41-LABEL: define i32 @nonconst_length(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-SSE41-NEXT:    ret i32 [[M]]
;
; X64-AVX1-LABEL: define i32 @nonconst_length(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX1-NEXT:    ret i32 [[M]]
;
; X64-AVX2-LABEL: define i32 @nonconst_length(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX2-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-256-LABEL: define i32 @nonconst_length(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512BW-LABEL: define i32 @nonconst_length(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512BW-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-256-LABEL: define i32 @nonconst_length(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    ret i32 [[M]]
;
; X64-AVX512F-LABEL: define i32 @nonconst_length(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512F-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX2-LABEL: define i32 @nonconst_length(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    ret i32 [[M]]
;
; X64-MIC-AVX512F-LABEL: define i32 @nonconst_length(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    ret i32 [[M]]
;




  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 %size) nounwind
  ret i32 %m
}

define i1 @nonconst_length_eq(ptr %X, ptr %Y, i64 %size) nounwind {
; X64-LABEL: define i1 @nonconst_length_eq(
; X64-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR0]] {
; X64-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR0]]
; X64-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-NEXT:    ret i1 [[C]]
;
; X64-SSE41-LABEL: define i1 @nonconst_length_eq(
; X64-SSE41-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-SSE41-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-SSE41-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-SSE41-NEXT:    ret i1 [[C]]
;
; X64-AVX1-LABEL: define i1 @nonconst_length_eq(
; X64-AVX1-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX1-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX1-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX1-NEXT:    ret i1 [[C]]
;
; X64-AVX2-LABEL: define i1 @nonconst_length_eq(
; X64-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX2-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-256-LABEL: define i1 @nonconst_length_eq(
; X64-AVX512BW-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512BW-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512BW-LABEL: define i1 @nonconst_length_eq(
; X64-AVX512BW-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512BW-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512BW-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512BW-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-256-LABEL: define i1 @nonconst_length_eq(
; X64-AVX512F-256-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512F-256-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512F-256-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-256-NEXT:    ret i1 [[C]]
;
; X64-AVX512F-LABEL: define i1 @nonconst_length_eq(
; X64-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-AVX512F-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX2-LABEL: define i1 @nonconst_length_eq(
; X64-MIC-AVX2-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX2-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-MIC-AVX2-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX2-NEXT:    ret i1 [[C]]
;
; X64-MIC-AVX512F-LABEL: define i1 @nonconst_length_eq(
; X64-MIC-AVX512F-SAME: ptr [[X:%.*]], ptr [[Y:%.*]], i64 [[SIZE:%.*]]) #[[ATTR1]] {
; X64-MIC-AVX512F-NEXT:    [[M:%.*]] = tail call i32 @memcmp(ptr [[X]], ptr [[Y]], i64 [[SIZE]]) #[[ATTR5]]
; X64-MIC-AVX512F-NEXT:    [[C:%.*]] = icmp eq i32 [[M]], 0
; X64-MIC-AVX512F-NEXT:    ret i1 [[C]]
;





  %m = tail call i32 @memcmp(ptr %X, ptr %Y, i64 %size) nounwind
  %c = icmp eq i32 %m, 0
  ret i1 %c
}
